import pandas as pd
import hydra
from omegaconf import DictConfig, OmegaConf
import logging
import os
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from transformers import RobertaTokenizer

from model import get_model
from data import ReceiptForgeryDataset
from trainer import ImageTrainer, TextTrainer
from util import set_seed, FocalLoss

@hydra.main(config_path="conf", config_name="config", version_base=None)
def main(cfg: DictConfig):
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê¸°ë³¸ ì„¸íŒ…
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger = logging.getLogger(__name__)
    logger.info("\n" + OmegaConf.to_yaml(cfg))
    set_seed(cfg.seed)

    # Hydraê°€ ìƒì„±í•œ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
    work_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir
    logger.info(f"ğŸ’¾ Outputs will be saved in: {work_dir}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„°ì…‹ & ë¡œë” ì¤€ë¹„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    base_dir = cfg.base_dir
    img_transform = transforms.Compose([
        transforms.Resize((512, 512)),

        # ìƒ‰ìƒ ë³€í˜• (ë„ˆë¬´ ê°•í•˜ë©´ ì•ˆë¨)
        transforms.ColorJitter(
            brightness=0.1,   # ë°ê¸° ë³€í™” ì¤„ì„
            contrast=0.1,     # ëŒ€ë¹„ ë³€í™” ì¤„ì„
            saturation=0.05,  # ì±„ë„ ë³€í™” ì¤„ì„
            hue=0.01          # ìƒ‰ì¡° ë³€í™” ì¤„ì„
        ),

        # ëœë¤ íšŒì „ (ì˜ìˆ˜ì¦ì€ ë³´í†µ ì•½ê°„ë§Œ ê¸°ìš¸ì–´ì§)
        transforms.RandomRotation(degrees=1.5, fill=255),

        # ì•½í•œ affine ë³€í˜• (ì´ë™/ìŠ¤ì¼€ì¼ ë²”ìœ„ ì¶•ì†Œ)
        transforms.RandomAffine(
            degrees=0,
            translate=(0.02, 0.02),  # 2% ë²”ìœ„ ì´ë™
            shear=1,                 # ê¸°ìš¸ê¸° ì¤„ì„
            scale=(0.98, 1.02),      # ìŠ¤ì¼€ì¼ ë³€í™”ë¥¼ ìµœì†Œí™”
            fill=255
        ),

        # GaussianBlur í™•ë¥ ë„ ì¤„ì´ê³  kernel ì‘ê²Œ
        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.1),

        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225]),
    ])

    tokenizer = RobertaTokenizer.from_pretrained("roberta-base")

    train_dataset = ReceiptForgeryDataset(
        csv_path=os.path.join(base_dir, cfg.train_csv),
        base_dir=base_dir,
        split="train",
        image_transform=img_transform,
        text_tokenizer=tokenizer,
        max_length=cfg.max_length
    )
    val_dataset = ReceiptForgeryDataset(
        csv_path=os.path.join(base_dir, cfg.val_csv),
        base_dir=base_dir,
        split="val",
        image_transform=img_transform,
        text_tokenizer=tokenizer,
        max_length=cfg.max_length
    )
    test_dataset = ReceiptForgeryDataset(
        csv_path=os.path.join(base_dir, cfg.test_csv),
        base_dir=base_dir,
        split="test",
        image_transform=img_transform,
        text_tokenizer=tokenizer,
        max_length=cfg.max_length
    )

    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers)
    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ëª¨ë¸ ì„ íƒ ë° Trainer ì¤€ë¹„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if cfg.model_type == "image":
        model = get_model("resnet50")
        optimizer = optim.Adam(model.parameters(), lr=cfg.image_lr)
        # ==========================
        # âœ¨ FocalLoss ì ìš©
        # ==========================
        criterion = FocalLoss(gamma=2.0, alpha=[1.0, 2.0], reduction='mean')
       
        trainer = ImageTrainer(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            logger=logger,
            scheduler=None,
            device=device,
            log_dir=os.path.join(work_dir, "runs"),
            patience=cfg.patience,
            save_path=os.path.join(work_dir, "best_image_model.pth")
        )
    elif cfg.model_type == "text":
        model = get_model("roberta")
        optimizer = optim.AdamW(model.parameters(), lr=cfg.text_lr)
        # ==========================
        # âœ¨ FocalLoss ì ìš©
        # ==========================
        criterion = FocalLoss(gamma=2.0, alpha=[1.0, 2.0], reduction='mean')
        trainer = TextTrainer(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            logger=logger,
            scheduler=None,
            device=device,
            log_dir=os.path.join(work_dir, "runs"),
            patience=cfg.patience,
            save_path=os.path.join(work_dir, "best_text_model.pth")
        )
    else:
        raise ValueError(f"Unknown model_type: {cfg.model_type}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í•™ìŠµ ì‹œì‘
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    trainer.training(train_loader, val_loader, cfg.epochs)
    trainer.test(test_loader)

if __name__ == "__main__":
    main()
