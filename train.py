import hydra
from omegaconf import DictConfig, OmegaConf
import logging
import os
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from transformers import RobertaTokenizer

from model import get_model
from data import ReceiptForgeryDataset
from trainer import ImageTrainer, TextTrainer
from util import set_seed

@hydra.main(config_path="conf", config_name="config", version_base=None)
def main(cfg: DictConfig):
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê¸°ë³¸ ì„¸íŒ…
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger = logging.getLogger(__name__)
    logger.info("\n" + OmegaConf.to_yaml(cfg))
    set_seed(cfg.seed)

    # Hydraê°€ ìƒì„±í•œ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
    work_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir
    logger.info(f"ğŸ’¾ Outputs will be saved in: {work_dir}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°ì´í„°ì…‹ & ë¡œë” ì¤€ë¹„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    base_dir = cfg.base_dir
    img_transform = transforms.Compose([
        # í¬ê¸° ì¡°ì •
        transforms.Resize((256, 256)),
        transforms.RandomResizedCrop(224, scale=(0.9, 1.0), ratio=(0.9, 1.1)),
        
        # ë°ê¸°/ëŒ€ë¹„/ì±„ë„/ìƒ‰ì¡° ì•½ê°„ ë³€í™”
        transforms.ColorJitter(
            brightness=0.2,  # ë°ê¸°
            contrast=0.2,    # ëŒ€ë¹„
            saturation=0.1,  # ì±„ë„
            hue=0.02         # ìƒ‰ì¡°
        ),

        # ì¢Œìš° ë’¤ì§‘ê¸° (ì˜ìˆ˜ì¦ì€ ëŒ€ì¹­ì ì´ë¼ í° ë¬¸ì œ ì—†ì§€ë§Œ ì„¸ë¡œí…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ False)
        # transforms.RandomHorizontalFlip(p=0.5),  # í•„ìš”í•˜ë©´ ì‚¬ìš©

        # ì•½ê°„ì˜ íšŒì „ (ì˜ìˆ˜ì¦ì´ ì•½ê°„ ê¸°ìš¸ì–´ì§ˆ ìˆ˜ ìˆìŒ)
        transforms.RandomRotation(degrees=2.0, expand=False, fill=255),

        # ëœë¤í•œ ë¯¸ì„¸í•œ affine ë³€í˜• (ì•½ê°„ì˜ ì´ë™/ê¸°ìš¸ì„)
        transforms.RandomAffine(
            degrees=0,
            translate=(0.02, 0.02),  # ìµœëŒ€ 2% ì´ë™
            shear=2,                # ì•½ê°„ì˜ ê¸°ìš¸ì„
            fill=255                # ë°°ê²½ìƒ‰ì„ í°ìƒ‰ìœ¼ë¡œ ì±„ì›€
        ),

        # í…ì„œ ë³€í™˜
        transforms.ToTensor(),

        # Normalize (í•„ìš”í•˜ë‹¤ë©´ ImageNet ê¸°ì¤€)
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
    ])

    tokenizer = RobertaTokenizer.from_pretrained("roberta-base")

    train_dataset = ReceiptForgeryDataset(
        csv_path=os.path.join(base_dir, cfg.train_csv),
        base_dir=base_dir,
        split="train",
        image_transform=img_transform,
        text_tokenizer=tokenizer,
        max_length=cfg.max_length
    )
    val_dataset = ReceiptForgeryDataset(
        csv_path=os.path.join(base_dir, cfg.val_csv),
        base_dir=base_dir,
        split="val",
        image_transform=img_transform,
        text_tokenizer=tokenizer,
        max_length=cfg.max_length
    )
    test_dataset = ReceiptForgeryDataset(
        csv_path=os.path.join(base_dir, cfg.test_csv),
        base_dir=base_dir,
        split="test",
        image_transform=img_transform,
        text_tokenizer=tokenizer,
        max_length=cfg.max_length
    )

    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers)
    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ëª¨ë¸ ì„ íƒ ë° Trainer ì¤€ë¹„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if cfg.model_type == "image":
        model = get_model("resnet50")
        optimizer = optim.Adam(model.parameters(), lr=cfg.image_lr)
        criterion = nn.CrossEntropyLoss()
        trainer = ImageTrainer(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            logger=logger,
            scheduler=None,
            device=device,
            log_dir=os.path.join(work_dir, "runs"),
            patience=cfg.patience,
            save_path=os.path.join(work_dir, "best_image_model.pth")
        )
    elif cfg.model_type == "text":
        model = get_model("roberta")
        optimizer = optim.AdamW(model.parameters(), lr=cfg.text_lr)
        criterion = nn.CrossEntropyLoss()
        trainer = TextTrainer(
            model=model,
            optimizer=optimizer,
            criterion=criterion,
            logger=logger,
            scheduler=None,
            device=device,
            log_dir=os.path.join(work_dir, "runs"),
            patience=cfg.patience,
            save_path=os.path.join(work_dir, "best_text_model.pth")
        )
    else:
        raise ValueError(f"Unknown model_type: {cfg.model_type}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í•™ìŠµ ì‹œì‘
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    trainer.training(train_loader, val_loader, cfg.epochs)
    trainer.test(test_loader)

if __name__ == "__main__":
    main()
